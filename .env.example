# Agentic Forge Configuration
# Copy this file to .env and fill in your values

# ============================================
# LLM API Keys
# ============================================

# Anthropic API Key (for Claude models)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (for GPT models)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# ============================================
# Server Configuration
# ============================================

# Server host and port
SERVER_HOST=127.0.0.1
SERVER_PORT=8080

# Log level: error, warn, info, debug, trace
RUST_LOG=info

# ============================================
# Agent Configuration
# ============================================

# Default LLM provider: anthropic, openai, mock
DEFAULT_LLM_PROVIDER=anthropic

# Default model for new agents
DEFAULT_MODEL=claude-3-5-sonnet-20241022

# Maximum tokens per request
MAX_TOKENS=4096

# Default temperature for LLM requests
DEFAULT_TEMPERATURE=0.7

# ============================================
# Database Configuration
# ============================================

# Database path (SQLite)
DATABASE_PATH=./data/agentic.db

# Enable persistence
ENABLE_PERSISTENCE=true

# ============================================
# Security Configuration
# ============================================

# Enable authentication
ENABLE_AUTH=false

# API key for accessing the system (if auth enabled)
API_KEY=your_secure_api_key_here

# Enable CORS
ENABLE_CORS=true

# Allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# ============================================
# Performance Configuration
# ============================================

# Maximum concurrent agent executions
MAX_CONCURRENT_EXECUTIONS=10

# Task queue size limit
TASK_QUEUE_SIZE=1000

# Agent timeout in seconds
AGENT_TIMEOUT=120

# Rate limit: requests per minute
RATE_LIMIT_PER_MINUTE=100

# ============================================
# Observability Configuration
# ============================================

# Enable OpenTelemetry tracing
ENABLE_TELEMETRY=false

# OpenTelemetry endpoint
OTEL_ENDPOINT=http://localhost:4317

# Enable metrics collection
ENABLE_METRICS=true

# ============================================
# Feature Flags
# ============================================

# Enable experimental features
ENABLE_EXPERIMENTS=false

# Enable agent evolution
ENABLE_EVOLUTION=true

# Enable knowledge sharing between agents
ENABLE_KNOWLEDGE_SHARING=true

# Enable autonomous agent generation
ENABLE_AUTO_GENERATION=false

# ============================================
# Development Configuration
# ============================================

# Enable development mode (more verbose logging, hot reload, etc.)
DEV_MODE=true

# Enable debug endpoints
ENABLE_DEBUG_ENDPOINTS=true

# Mock external services (for testing without API keys)
MOCK_EXTERNAL_SERVICES=false

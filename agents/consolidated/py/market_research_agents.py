# ðŸ” Market Research Specialized Agents
# First testbed implementation for Beyond-Enterprise Agentic Ecosystem
# Autonomous agents for market analysis, opportunity identification, and business development

import asyncio
import json
import uuid
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Set, Union, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
import logging
from abc import ABC, abstractmethod
import aiohttp
import numpy as np

# Optional sklearn imports with fallbacks
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except (ImportError, MemoryError, Exception) as e:
    # Fallback implementations
    SKLEARN_AVAILABLE = False
    print(f"Warning: sklearn not available ({e}), using fallback implementations")

    class TfidfVectorizer:
        def fit_transform(self, texts):
            return [[1.0] * len(texts)]
        def transform(self, texts):
            return [[1.0] * len(texts)]

    class KMeans:
        def __init__(self, n_clusters=3, random_state=42):
            self.n_clusters = n_clusters
        def fit_predict(self, data):
            return [0] * len(data)

try:
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
except ImportError:
    # Mock sentiment analyzer if not available
    class SentimentIntensityAnalyzer:
        def polarity_scores(self, text):
            return {'compound': 0.0, 'pos': 0.0, 'neu': 1.0, 'neg': 0.0}

# Import existing market research infrastructure
from .ai_service import MarketAnalysisAI
from .connectors.amazon_simple import AmazonConnector
from .connectors.google_trends_simple import GoogleTrendsConnector
from .apqc_agent_specialization_framework import APQCCategory, AgentSpecializationLevel, APQCAgentSpecialization
from .blockchain_agentic_protocol import BlockchainAgenticProtocol, TokenType, TransactionType

logger = logging.getLogger(__name__)

class MarketResearchCapability(Enum):
    """Specialized capabilities for market research agents"""
    TREND_ANALYSIS = "trend_analysis"
    SENTIMENT_ANALYSIS = "sentiment_analysis"
    COMPETITIVE_INTELLIGENCE = "competitive_intelligence"
    PRODUCT_DISCOVERY = "product_discovery"
    MARKET_SEGMENTATION = "market_segmentation"
    DEMAND_FORECASTING = "demand_forecasting"
    PRICING_OPTIMIZATION = "pricing_optimization"
    OPPORTUNITY_IDENTIFICATION = "opportunity_identification"
    BUSINESS_MODEL_GENERATION = "business_model_generation"
    RISK_ASSESSMENT = "risk_assessment"
    FINANCIAL_MODELING = "financial_modeling"
    IMPLEMENTATION_PLANNING = "implementation_planning"

class AgentStatus(Enum):
    """Status of market research agents"""
    INITIALIZING = "initializing"
    ACTIVE = "active"
    ANALYZING = "analyzing"
    COLLABORATING = "collaborating"
    LEARNING = "learning"
    IDLE = "idle"
    ERROR = "error"
    OFFLINE = "offline"

class InsightConfidence(Enum):
    """Confidence levels for agent insights"""
    LOW = "low"           # 0.0 - 0.4
    MEDIUM = "medium"     # 0.4 - 0.7
    HIGH = "high"         # 0.7 - 0.9
    VERY_HIGH = "very_high"  # 0.9 - 1.0

@dataclass
class MarketInsight:
    """Market insight generated by agents"""
    insight_id: str
    insight_type: str
    agent_id: str
    confidence_score: float

    # Core Content
    title: str
    description: str
    key_findings: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)

    # Data Sources
    data_sources: List[str] = field(default_factory=list)
    raw_data: Dict[str, Any] = field(default_factory=dict)

    # Market Context
    market_segment: Optional[str] = None
    target_audience: Optional[str] = None
    geographic_scope: Optional[str] = None
    time_horizon: Optional[str] = None

    # Business Impact
    revenue_potential: Optional[float] = None
    cost_implications: Optional[float] = None
    risk_factors: List[str] = field(default_factory=list)
    implementation_complexity: Optional[str] = None

    # Validation and Feedback
    validation_score: float = 0.0
    peer_reviews: List[str] = field(default_factory=list)
    human_feedback: Optional[str] = None

    # Metadata
    created_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    expires_at: Optional[str] = None

    # Collaboration
    related_insights: List[str] = field(default_factory=list)
    contributing_agents: List[str] = field(default_factory=list)

@dataclass
class BusinessOpportunity:
    """Business opportunity identified by agents"""
    opportunity_id: str
    opportunity_name: str
    opportunity_type: str
    discovering_agent: str

    # Opportunity Details
    description: str
    market_size: Optional[float] = None
    target_market: Optional[str] = None
    value_proposition: Optional[str] = None

    # Financial Projections
    revenue_projection_1y: Optional[float] = None
    revenue_projection_3y: Optional[float] = None
    investment_required: Optional[float] = None
    roi_estimate: Optional[float] = None
    payback_period: Optional[float] = None

    # Market Analysis
    competition_level: Optional[str] = None
    market_trends: List[str] = field(default_factory=list)
    barriers_to_entry: List[str] = field(default_factory=list)
    success_factors: List[str] = field(default_factory=list)

    # Implementation
    implementation_timeline: Optional[str] = None
    required_capabilities: List[str] = field(default_factory=list)
    risk_assessment: Dict[str, float] = field(default_factory=dict)
    next_steps: List[str] = field(default_factory=list)

    # Validation
    confidence_score: float = 0.0
    validation_status: str = "identified"  # identified, analyzed, validated, approved, rejected
    supporting_insights: List[str] = field(default_factory=list)

    # Collaboration
    assigned_agents: List[str] = field(default_factory=list)
    stakeholder_feedback: List[Dict[str, str]] = field(default_factory=list)

    # Metadata
    created_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    last_updated: str = field(default_factory=lambda: datetime.utcnow().isoformat())

class BaseMarketResearchAgent(ABC):
    """Base class for all market research agents"""

    def __init__(self, agent_id: str, agent_name: str, capabilities: List[MarketResearchCapability]):
        self.agent_id = agent_id
        self.agent_name = agent_name
        self.capabilities = capabilities
        self.status = AgentStatus.INITIALIZING

        # Core Services
        self.ai_service: Optional[MarketAnalysisAI] = None
        self.blockchain_protocol: Optional[BlockchainAgenticProtocol] = None

        # Performance Tracking
        self.insights_generated = 0
        self.opportunities_identified = 0
        self.collaboration_count = 0
        self.accuracy_score = 0.85

        # Learning and Evolution
        self.learning_objectives: List[str] = []
        self.performance_history: List[Dict[str, Any]] = []
        self.feedback_log: List[Dict[str, Any]] = []

        # State Management
        self.current_tasks: List[str] = []
        self.active_collaborations: List[str] = []
        self.knowledge_base: Dict[str, Any] = {}

        # Configuration
        self.config: Dict[str, Any] = {
            "max_concurrent_tasks": 5,
            "insight_confidence_threshold": 0.7,
            "collaboration_timeout": 1800,  # 30 minutes
            "learning_rate": 0.1
        }

    async def initialize(self, ai_service: MarketAnalysisAI, blockchain_protocol: BlockchainAgenticProtocol):
        """Initialize the agent with required services"""
        self.ai_service = ai_service
        self.blockchain_protocol = blockchain_protocol

        # Register with blockchain protocol
        await self._register_with_blockchain()

        # Initialize capabilities
        await self._initialize_capabilities()

        self.status = AgentStatus.ACTIVE
        logger.info(f"âœ… {self.agent_name} initialized and ready")

    @abstractmethod
    async def analyze(self, data: Dict[str, Any]) -> List[MarketInsight]:
        """Abstract method for agent-specific analysis"""
        pass

    @abstractmethod
    async def collaborate(self, other_agent_id: str, task: Dict[str, Any]) -> Dict[str, Any]:
        """Abstract method for agent collaboration"""
        pass

    async def generate_insight(self, analysis_type: str, data: Dict[str, Any]) -> MarketInsight:
        """Generate market insight from analysis"""
        try:
            self.status = AgentStatus.ANALYZING

            # Perform analysis using AI service
            analysis_prompt = self._create_analysis_prompt(analysis_type, data)
            ai_response = await self.ai_service.generate_analysis(analysis_prompt)

            # Extract insights from AI response
            insight = self._extract_insight_from_response(ai_response, analysis_type, data)

            # Validate insight confidence
            insight.confidence_score = await self._calculate_confidence_score(insight)

            # Store insight
            await self._store_insight(insight)

            # Update performance metrics
            self.insights_generated += 1
            await self._update_performance_metrics()

            self.status = AgentStatus.ACTIVE
            return insight

        except Exception as e:
            logger.error(f"âŒ {self.agent_name} insight generation failed: {e}")
            self.status = AgentStatus.ERROR
            raise

    async def identify_opportunity(self, market_data: Dict[str, Any]) -> Optional[BusinessOpportunity]:
        """Identify business opportunities from market analysis"""
        try:
            # Analyze market data for opportunity patterns
            opportunity_indicators = await self._analyze_opportunity_indicators(market_data)

            if opportunity_indicators["opportunity_score"] > 0.7:
                # Generate business opportunity
                opportunity = await self._generate_business_opportunity(market_data, opportunity_indicators)

                # Validate opportunity
                opportunity.confidence_score = await self._validate_opportunity(opportunity)

                if opportunity.confidence_score > 0.6:
                    # Store opportunity
                    await self._store_opportunity(opportunity)

                    # Reward agent for opportunity identification
                    await self._reward_opportunity_identification()

                    self.opportunities_identified += 1
                    logger.info(f"ðŸŽ¯ {self.agent_name} identified opportunity: {opportunity.opportunity_name}")

                    return opportunity

            return None

        except Exception as e:
            logger.error(f"âŒ {self.agent_name} opportunity identification failed: {e}")
            return None

    async def learn_from_feedback(self, feedback: Dict[str, Any]):
        """Learn and adapt from feedback"""
        try:
            # Record feedback
            self.feedback_log.append({
                "timestamp": datetime.utcnow().isoformat(),
                "feedback": feedback,
                "agent_state": asdict(self)
            })

            # Update accuracy score based on feedback
            if feedback.get("type") == "accuracy":
                accuracy_update = feedback.get("score", 0.5)
                self.accuracy_score = (self.accuracy_score * 0.9) + (accuracy_update * 0.1)

            # Adjust analysis approach based on feedback
            await self._adjust_analysis_approach(feedback)

            # Update learning objectives
            await self._update_learning_objectives(feedback)

            logger.info(f"ðŸ“š {self.agent_name} learned from feedback")

        except Exception as e:
            logger.error(f"âŒ {self.agent_name} learning failed: {e}")

    # Helper Methods

    async def _register_with_blockchain(self):
        """Register agent with blockchain protocol"""
        if self.blockchain_protocol:
            # Create agent wallet
            await self.blockchain_protocol.create_agent_wallet(self.agent_id)

            # Mint capability NFTs
            for capability in self.capabilities:
                await self.blockchain_protocol.mint_capability_nft(
                    self.agent_id,
                    {
                        "name": capability.value,
                        "category": "market_research",
                        "proficiency_level": 0.8,
                        "authority": "system"
                    }
                )

    async def _initialize_capabilities(self):
        """Initialize agent capabilities"""
        for capability in self.capabilities:
            # Load capability-specific models and data
            capability_config = await self._load_capability_config(capability)
            self.knowledge_base[capability.value] = capability_config

    def _create_analysis_prompt(self, analysis_type: str, data: Dict[str, Any]) -> str:
        """Create AI analysis prompt"""
        base_prompt = f"""
        As a {self.agent_name}, perform {analysis_type} analysis on the following data:

        Data: {json.dumps(data, indent=2)}

        Please provide:
        1. Key insights and findings
        2. Market implications
        3. Recommendations
        4. Confidence assessment
        5. Risk factors

        Format the response as structured JSON.
        """
        return base_prompt

    def _extract_insight_from_response(self, ai_response: Dict[str, Any], analysis_type: str, data: Dict[str, Any]) -> MarketInsight:
        """Extract structured insight from AI response"""
        return MarketInsight(
            insight_id=str(uuid.uuid4()),
            insight_type=analysis_type,
            agent_id=self.agent_id,
            confidence_score=0.0,  # Will be calculated
            title=ai_response.get("title", f"{analysis_type} Analysis"),
            description=ai_response.get("description", ""),
            key_findings=ai_response.get("key_findings", []),
            recommendations=ai_response.get("recommendations", []),
            data_sources=[f"{self.agent_name}_analysis"],
            raw_data=data
        )

    async def _calculate_confidence_score(self, insight: MarketInsight) -> float:
        """Calculate confidence score for insight"""
        factors = [
            len(insight.key_findings) * 0.1,  # More findings = higher confidence
            self.accuracy_score,  # Agent's historical accuracy
            min(1.0, len(insight.data_sources) * 0.2),  # Multiple sources
            0.8 if insight.recommendations else 0.5  # Has recommendations
        ]
        return min(1.0, sum(factors) / len(factors))

    async def _store_insight(self, insight: MarketInsight):
        """Store insight in knowledge base and blockchain"""
        # Store locally
        self.knowledge_base[insight.insight_id] = insight

        # Create blockchain transaction for insight
        if self.blockchain_protocol:
            await self.blockchain_protocol.execute_autonomous_transaction(
                from_agent=self.agent_id,
                to_agent="knowledge_marketplace",
                transaction_type=TransactionType.KNOWLEDGE_SALE,
                amount=10.0,  # Base value for insight
                transaction_data={"insight_id": insight.insight_id, "type": "market_insight"}
            )

    async def _update_performance_metrics(self):
        """Update agent performance metrics"""
        performance_data = {
            "insights_generated": self.insights_generated,
            "opportunities_identified": self.opportunities_identified,
            "accuracy_score": self.accuracy_score,
            "collaboration_count": self.collaboration_count,
            "timestamp": datetime.utcnow().isoformat()
        }

        self.performance_history.append(performance_data)

        # Reward performance with tokens
        if self.blockchain_protocol and self.insights_generated % 10 == 0:
            await self.blockchain_protocol.reward_performance(
                self.agent_id,
                {"performance_milestone": "10_insights", "quality_score": self.accuracy_score}
            )

    # Placeholder implementations
    async def _load_capability_config(self, capability: MarketResearchCapability) -> Dict[str, Any]:
        return {"capability": capability.value, "initialized": True}

    async def _analyze_opportunity_indicators(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        return {"opportunity_score": 0.8, "indicators": ["high_demand", "low_competition"]}

    async def _generate_business_opportunity(self, market_data: Dict[str, Any], indicators: Dict[str, Any]) -> BusinessOpportunity:
        return BusinessOpportunity(
            opportunity_id=str(uuid.uuid4()),
            opportunity_name="AI-Generated Market Opportunity",
            opportunity_type="product_development",
            discovering_agent=self.agent_id,
            description="Market opportunity identified through autonomous analysis"
        )

    async def _validate_opportunity(self, opportunity: BusinessOpportunity) -> float:
        return 0.75

    async def _store_opportunity(self, opportunity: BusinessOpportunity):
        self.knowledge_base[opportunity.opportunity_id] = opportunity

    async def _reward_opportunity_identification(self):
        if self.blockchain_protocol:
            await self.blockchain_protocol.reward_performance(
                self.agent_id,
                {"achievement": "opportunity_identification", "value": "high"}
            )

    async def _adjust_analysis_approach(self, feedback: Dict[str, Any]):
        pass

    async def _update_learning_objectives(self, feedback: Dict[str, Any]):
        pass

class TrendAnalysisAgent(BaseMarketResearchAgent):
    """Specialized agent for trend analysis and forecasting"""

    def __init__(self):
        super().__init__(
            agent_id="trend_analysis_agent",
            agent_name="Trend Analysis Specialist",
            capabilities=[
                MarketResearchCapability.TREND_ANALYSIS,
                MarketResearchCapability.DEMAND_FORECASTING,
                MarketResearchCapability.SENTIMENT_ANALYSIS
            ]
        )
        self.google_trends_connector = GoogleTrendsConnector()
        self.trend_models: Dict[str, Any] = {}

    async def analyze(self, data: Dict[str, Any]) -> List[MarketInsight]:
        """Perform comprehensive trend analysis"""
        try:
            insights = []

            # Analyze search trends
            if "keywords" in data:
                trend_insight = await self._analyze_search_trends(data["keywords"])
                insights.append(trend_insight)

            # Analyze sentiment trends
            if "text_data" in data:
                sentiment_insight = await self._analyze_sentiment_trends(data["text_data"])
                insights.append(sentiment_insight)

            # Generate demand forecast
            if "historical_data" in data:
                forecast_insight = await self._generate_demand_forecast(data["historical_data"])
                insights.append(forecast_insight)

            return insights

        except Exception as e:
            logger.error(f"âŒ Trend analysis failed: {e}")
            return []

    async def collaborate(self, other_agent_id: str, task: Dict[str, Any]) -> Dict[str, Any]:
        """Collaborate with other agents on trend analysis"""
        try:
            self.status = AgentStatus.COLLABORATING
            self.collaboration_count += 1

            if task.get("type") == "cross_validate_trends":
                # Share trend data with other agent
                trend_data = await self._prepare_trend_data_for_sharing(task["keywords"])

                return {
                    "status": "success",
                    "data": trend_data,
                    "agent_id": self.agent_id,
                    "collaboration_type": "trend_validation"
                }

            return {"status": "unsupported_task", "message": "Task type not supported"}

        except Exception as e:
            logger.error(f"âŒ Collaboration failed: {e}")
            return {"status": "error", "message": str(e)}
        finally:
            self.status = AgentStatus.ACTIVE

    async def _analyze_search_trends(self, keywords: List[str]) -> MarketInsight:
        """Analyze Google Trends data for keywords"""
        # Integrate with existing Google Trends connector
        trends_data = await self.google_trends_connector.get_trends_data(keywords)

        # AI analysis of trends
        analysis_prompt = f"""
        Analyze these Google Trends data for market insights:
        Keywords: {keywords}
        Trends Data: {trends_data}

        Identify:
        1. Rising trends and declining patterns
        2. Seasonal variations
        3. Regional differences
        4. Correlation opportunities
        5. Market timing recommendations
        """

        ai_response = await self.ai_service.generate_analysis(analysis_prompt)

        return self._extract_insight_from_response(ai_response, "trend_analysis", trends_data)

    async def _analyze_sentiment_trends(self, text_data: List[str]) -> MarketInsight:
        """Analyze sentiment trends in text data"""
        # Implement sentiment analysis
        sentiment_scores = []
        for text in text_data:
            # Use AI service for sentiment analysis
            sentiment_prompt = f"Analyze sentiment of: {text}"
            sentiment_result = await self.ai_service.generate_analysis(sentiment_prompt)
            sentiment_scores.append(sentiment_result.get("sentiment_score", 0.5))

        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)

        insight = MarketInsight(
            insight_id=str(uuid.uuid4()),
            insight_type="sentiment_analysis",
            agent_id=self.agent_id,
            confidence_score=0.8,
            title="Sentiment Trend Analysis",
            description=f"Average sentiment score: {avg_sentiment:.2f}",
            key_findings=[
                f"Overall sentiment: {'Positive' if avg_sentiment > 0.6 else 'Negative' if avg_sentiment < 0.4 else 'Neutral'}",
                f"Sentiment variation: {max(sentiment_scores) - min(sentiment_scores):.2f}",
                f"Sample size: {len(text_data)} items"
            ],
            raw_data={"sentiment_scores": sentiment_scores, "text_count": len(text_data)}
        )

        return insight

    async def _generate_demand_forecast(self, historical_data: Dict[str, Any]) -> MarketInsight:
        """Generate demand forecast from historical data"""
        # Simple trend analysis (could be enhanced with ML models)
        data_points = historical_data.get("data_points", [])

        if len(data_points) < 3:
            return MarketInsight(
                insight_id=str(uuid.uuid4()),
                insight_type="demand_forecast",
                agent_id=self.agent_id,
                confidence_score=0.3,
                title="Insufficient Data for Forecasting",
                description="Need more historical data points for accurate forecasting"
            )

        # Calculate trend
        values = [point.get("value", 0) for point in data_points]
        trend = (values[-1] - values[0]) / len(values)

        # Generate forecast
        forecast_periods = 6  # 6 periods ahead
        forecasted_values = []
        for i in range(1, forecast_periods + 1):
            forecast_value = values[-1] + (trend * i)
            forecasted_values.append(forecast_value)

        insight = MarketInsight(
            insight_id=str(uuid.uuid4()),
            insight_type="demand_forecast",
            agent_id=self.agent_id,
            confidence_score=0.7,
            title="Demand Forecast Analysis",
            description=f"Forecasted {forecast_periods} periods ahead with {trend:.2f} trend",
            key_findings=[
                f"Historical trend: {trend:.2f} per period",
                f"Next period forecast: {forecasted_values[0]:.2f}",
                f"6-period forecast: {forecasted_values[-1]:.2f}",
                f"Trend direction: {'Upward' if trend > 0 else 'Downward' if trend < 0 else 'Stable'}"
            ],
            raw_data={"historical": values, "forecast": forecasted_values, "trend": trend}
        )

        return insight

    async def _prepare_trend_data_for_sharing(self, keywords: List[str]) -> Dict[str, Any]:
        """Prepare trend data for sharing with other agents"""
        return {
            "keywords": keywords,
            "analysis_timestamp": datetime.utcnow().isoformat(),
            "agent_expertise": [cap.value for cap in self.capabilities],
            "data_quality_score": 0.85
        }

class ProductDiscoveryAgent(BaseMarketResearchAgent):
    """Specialized agent for product discovery and competitive analysis"""

    def __init__(self):
        super().__init__(
            agent_id="product_discovery_agent",
            agent_name="Product Discovery Specialist",
            capabilities=[
                MarketResearchCapability.PRODUCT_DISCOVERY,
                MarketResearchCapability.COMPETITIVE_INTELLIGENCE,
                MarketResearchCapability.PRICING_OPTIMIZATION
            ]
        )
        self.amazon_connector = AmazonConnector()
        self.product_database: Dict[str, Any] = {}

    async def analyze(self, data: Dict[str, Any]) -> List[MarketInsight]:
        """Perform comprehensive product analysis"""
        try:
            insights = []

            # Analyze product market
            if "search_terms" in data:
                product_insight = await self._analyze_product_market(data["search_terms"])
                insights.append(product_insight)

            # Analyze pricing
            if "products" in data:
                pricing_insight = await self._analyze_pricing_patterns(data["products"])
                insights.append(pricing_insight)

            # Identify gaps
            if "category" in data:
                gap_insight = await self._identify_market_gaps(data["category"])
                insights.append(gap_insight)

            return insights

        except Exception as e:
            logger.error(f"âŒ Product analysis failed: {e}")
            return []

    async def collaborate(self, other_agent_id: str, task: Dict[str, Any]) -> Dict[str, Any]:
        """Collaborate with other agents on product analysis"""
        try:
            self.status = AgentStatus.COLLABORATING
            self.collaboration_count += 1

            if task.get("type") == "product_trend_correlation":
                # Correlate product data with trends
                product_data = await self._prepare_product_data_for_correlation(task.get("products", []))

                return {
                    "status": "success",
                    "data": product_data,
                    "agent_id": self.agent_id,
                    "collaboration_type": "product_correlation"
                }

            return {"status": "unsupported_task", "message": "Task type not supported"}

        except Exception as e:
            logger.error(f"âŒ Collaboration failed: {e}")
            return {"status": "error", "message": str(e)}
        finally:
            self.status = AgentStatus.ACTIVE

    async def _analyze_product_market(self, search_terms: List[str]) -> MarketInsight:
        """Analyze product market using Amazon data"""
        # Use existing Amazon connector
        all_products = []
        for term in search_terms:
            products = await self.amazon_connector.search_products(term)
            all_products.extend(products)

        # AI analysis of product data
        analysis_prompt = f"""
        Analyze this product market data:
        Search Terms: {search_terms}
        Total Products Found: {len(all_products)}
        Sample Products: {all_products[:5]}

        Provide insights on:
        1. Market saturation
        2. Price ranges and competition
        3. Popular features and trends
        4. Gaps and opportunities
        5. Customer satisfaction patterns
        """

        ai_response = await self.ai_service.generate_analysis(analysis_prompt)

        return self._extract_insight_from_response(ai_response, "product_market_analysis", {
            "search_terms": search_terms,
            "product_count": len(all_products),
            "sample_products": all_products[:10]
        })

    async def _analyze_pricing_patterns(self, products: List[Dict[str, Any]]) -> MarketInsight:
        """Analyze pricing patterns in product data"""
        prices = [float(p.get("price", 0)) for p in products if p.get("price")]

        if not prices:
            return MarketInsight(
                insight_id=str(uuid.uuid4()),
                insight_type="pricing_analysis",
                agent_id=self.agent_id,
                confidence_score=0.2,
                title="No Pricing Data Available",
                description="Unable to analyze pricing patterns due to lack of data"
            )

        # Calculate pricing statistics
        avg_price = sum(prices) / len(prices)
        min_price = min(prices)
        max_price = max(prices)
        price_range = max_price - min_price

        # Identify pricing tiers
        low_tier = [p for p in prices if p < avg_price * 0.7]
        mid_tier = [p for p in prices if avg_price * 0.7 <= p <= avg_price * 1.3]
        high_tier = [p for p in prices if p > avg_price * 1.3]

        insight = MarketInsight(
            insight_id=str(uuid.uuid4()),
            insight_type="pricing_analysis",
            agent_id=self.agent_id,
            confidence_score=0.8,
            title="Product Pricing Analysis",
            description=f"Analysis of {len(products)} products with pricing data",
            key_findings=[
                f"Average price: ${avg_price:.2f}",
                f"Price range: ${min_price:.2f} - ${max_price:.2f}",
                f"Low tier products: {len(low_tier)} ({len(low_tier)/len(prices)*100:.1f}%)",
                f"Mid tier products: {len(mid_tier)} ({len(mid_tier)/len(prices)*100:.1f}%)",
                f"High tier products: {len(high_tier)} ({len(high_tier)/len(prices)*100:.1f}%)"
            ],
            recommendations=[
                f"Optimal pricing range appears to be ${avg_price*0.8:.2f} - ${avg_price*1.2:.2f}",
                "Consider targeting mid-tier pricing for market penetration",
                "Monitor price elasticity in identified tiers"
            ],
            raw_data={
                "prices": prices,
                "statistics": {
                    "average": avg_price,
                    "min": min_price,
                    "max": max_price,
                    "range": price_range
                },
                "tiers": {
                    "low": len(low_tier),
                    "mid": len(mid_tier),
                    "high": len(high_tier)
                }
            }
        )

        return insight

    async def _identify_market_gaps(self, category: str) -> MarketInsight:
        """Identify gaps in product market"""
        # This would typically involve comprehensive market analysis
        # For now, we'll create a placeholder implementation

        insight = MarketInsight(
            insight_id=str(uuid.uuid4()),
            insight_type="market_gap_analysis",
            agent_id=self.agent_id,
            confidence_score=0.6,
            title=f"Market Gap Analysis: {category}",
            description=f"Identified potential opportunities in {category} market",
            key_findings=[
                "Under-served price segments identified",
                "Feature combinations not widely available",
                "Geographic markets with limited competition"
            ],
            recommendations=[
                "Focus on mid-market segment with premium features",
                "Consider international expansion opportunities",
                "Develop products with identified feature gaps"
            ],
            raw_data={"category": category, "analysis_method": "competitive_analysis"}
        )

        return insight

    async def _prepare_product_data_for_correlation(self, products: List[str]) -> Dict[str, Any]:
        """Prepare product data for correlation analysis"""
        return {
            "products": products,
            "analysis_timestamp": datetime.utcnow().isoformat(),
            "agent_expertise": [cap.value for cap in self.capabilities],
            "data_quality_score": 0.82
        }

class OpportunityIdentificationAgent(BaseMarketResearchAgent):
    """Specialized agent for identifying and evaluating business opportunities"""

    def __init__(self):
        super().__init__(
            agent_id="opportunity_identification_agent",
            agent_name="Opportunity Identification Specialist",
            capabilities=[
                MarketResearchCapability.OPPORTUNITY_IDENTIFICATION,
                MarketResearchCapability.BUSINESS_MODEL_GENERATION,
                MarketResearchCapability.RISK_ASSESSMENT,
                MarketResearchCapability.FINANCIAL_MODELING
            ]
        )
        self.opportunity_models: Dict[str, Any] = {}
        self.business_model_templates: List[Dict[str, Any]] = []

    async def analyze(self, data: Dict[str, Any]) -> List[MarketInsight]:
        """Analyze data for business opportunities"""
        try:
            insights = []

            # Identify opportunities from market data
            opportunity_insight = await self._identify_opportunities(data)
            insights.append(opportunity_insight)

            # Generate business models for identified opportunities
            if "opportunities" in data:
                business_model_insight = await self._generate_business_models(data["opportunities"])
                insights.append(business_model_insight)

            # Assess risks for opportunities
            if "opportunity_data" in data:
                risk_insight = await self._assess_opportunity_risks(data["opportunity_data"])
                insights.append(risk_insight)

            return insights

        except Exception as e:
            logger.error(f"âŒ Opportunity analysis failed: {e}")
            return []

    async def collaborate(self, other_agent_id: str, task: Dict[str, Any]) -> Dict[str, Any]:
        """Collaborate with other agents on opportunity identification"""
        try:
            self.status = AgentStatus.COLLABORATING
            self.collaboration_count += 1

            if task.get("type") == "opportunity_validation":
                # Validate opportunities with other agents
                validation_data = await self._prepare_validation_data(task.get("opportunities", []))

                return {
                    "status": "success",
                    "data": validation_data,
                    "agent_id": self.agent_id,
                    "collaboration_type": "opportunity_validation"
                }

            return {"status": "unsupported_task", "message": "Task type not supported"}

        except Exception as e:
            logger.error(f"âŒ Collaboration failed: {e}")
            return {"status": "error", "message": str(e)}
        finally:
            self.status = AgentStatus.ACTIVE

    async def _identify_opportunities(self, data: Dict[str, Any]) -> MarketInsight:
        """Identify business opportunities from market data"""
        # AI-powered opportunity identification
        analysis_prompt = f"""
        Analyze this market data for business opportunities:
        {json.dumps(data, indent=2)}

        Identify:
        1. Market gaps and unmet needs
        2. Emerging trends with commercial potential
        3. Competitive weaknesses to exploit
        4. Technology disruption opportunities
        5. Regulatory or social changes creating opportunities

        For each opportunity, provide:
        - Market size estimate
        - Investment requirements
        - Timeline to market
        - Risk factors
        - Success probability
        """

        ai_response = await self.ai_service.generate_analysis(analysis_prompt)

        return self._extract_insight_from_response(ai_response, "opportunity_identification", data)

    async def _generate_business_models(self, opportunities: List[Dict[str, Any]]) -> MarketInsight:
        """Generate business models for identified opportunities"""
        business_models = []

        for opportunity in opportunities:
            # Generate business model using AI
            model_prompt = f"""
            Generate a business model for this opportunity:
            {json.dumps(opportunity, indent=2)}

            Include:
            1. Value proposition
            2. Target customer segments
            3. Revenue streams
            4. Key partnerships
            5. Cost structure
            6. Implementation strategy
            """

            model_response = await self.ai_service.generate_analysis(model_prompt)
            business_models.append(model_response)

        insight = MarketInsight(
            insight_id=str(uuid.uuid4()),
            insight_type="business_model_generation",
            agent_id=self.agent_id,
            confidence_score=0.75,
            title="Business Model Generation",
            description=f"Generated {len(business_models)} business models for identified opportunities",
            key_findings=[
                f"Business models created: {len(business_models)}",
                "Multiple revenue stream opportunities identified",
                "Partnership opportunities mapped",
                "Implementation timelines defined"
            ],
            recommendations=[
                "Prioritize models with highest ROI potential",
                "Validate assumptions with market research",
                "Develop MVP for top opportunities"
            ],
            raw_data={"business_models": business_models, "opportunities": opportunities}
        )

        return insight

    async def _assess_opportunity_risks(self, opportunity_data: Dict[str, Any]) -> MarketInsight:
        """Assess risks for business opportunities"""
        # Risk assessment using AI
        risk_prompt = f"""
        Assess risks for this business opportunity:
        {json.dumps(opportunity_data, indent=2)}

        Analyze:
        1. Market risks (competition, demand changes)
        2. Technical risks (implementation challenges)
        3. Financial risks (funding, profitability)
        4. Regulatory risks (compliance, policy changes)
        5. Operational risks (execution, scaling)

        Provide risk scores (1-10) and mitigation strategies.
        """

        risk_response = await self.ai_service.generate_analysis(risk_prompt)

        return self._extract_insight_from_response(risk_response, "risk_assessment", opportunity_data)

    async def _prepare_validation_data(self, opportunities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Prepare opportunity data for validation by other agents"""
        return {
            "opportunities": opportunities,
            "validation_timestamp": datetime.utcnow().isoformat(),
            "agent_expertise": [cap.value for cap in self.capabilities],
            "validation_criteria": ["market_size", "competition", "feasibility", "profitability"]
        }

# Market Research Agent Orchestrator

class MarketResearchAgentOrchestrator:
    """Orchestrates collaboration between market research agents"""

    def __init__(self):
        self.agents: Dict[str, BaseMarketResearchAgent] = {}
        self.active_collaborations: Dict[str, Dict[str, Any]] = {}
        self.insight_repository: Dict[str, MarketInsight] = {}
        self.opportunity_repository: Dict[str, BusinessOpportunity] = {}

    async def initialize(self, ai_service: MarketAnalysisAI, blockchain_protocol: BlockchainAgenticProtocol):
        """Initialize all market research agents"""
        # Create specialized agents
        self.agents["trend_analysis"] = TrendAnalysisAgent()
        self.agents["product_discovery"] = ProductDiscoveryAgent()
        self.agents["opportunity_identification"] = OpportunityIdentificationAgent()

        # Initialize each agent
        for agent in self.agents.values():
            await agent.initialize(ai_service, blockchain_protocol)

        logger.info("ðŸ¤– Market Research Agent Orchestrator initialized with all specialized agents")

    async def analyze_market_opportunity(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """Orchestrate comprehensive market opportunity analysis"""
        try:
            results = {
                "analysis_id": str(uuid.uuid4()),
                "timestamp": datetime.utcnow().isoformat(),
                "insights": [],
                "opportunities": [],
                "recommendations": [],
                "confidence_score": 0.0
            }

            # Step 1: Trend Analysis
            trend_insights = await self.agents["trend_analysis"].analyze(market_data)
            results["insights"].extend([asdict(insight) for insight in trend_insights])

            # Step 2: Product Discovery
            product_insights = await self.agents["product_discovery"].analyze(market_data)
            results["insights"].extend([asdict(insight) for insight in product_insights])

            # Step 3: Cross-Agent Collaboration
            collaboration_data = await self._orchestrate_collaboration(market_data)

            # Step 4: Opportunity Identification
            opportunity_data = {**market_data, **collaboration_data}
            opportunity_insights = await self.agents["opportunity_identification"].analyze(opportunity_data)
            results["insights"].extend([asdict(insight) for insight in opportunity_insights])

            # Step 5: Identify concrete business opportunities
            for agent in self.agents.values():
                opportunity = await agent.identify_opportunity(market_data)
                if opportunity:
                    results["opportunities"].append(asdict(opportunity))
                    self.opportunity_repository[opportunity.opportunity_id] = opportunity

            # Step 6: Generate final recommendations
            results["recommendations"] = await self._generate_final_recommendations(results)
            results["confidence_score"] = await self._calculate_analysis_confidence(results)

            logger.info(f"âœ… Market opportunity analysis completed: {results['analysis_id']}")
            return results

        except Exception as e:
            logger.error(f"âŒ Market opportunity analysis failed: {e}")
            raise

    async def _orchestrate_collaboration(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """Orchestrate collaboration between agents"""
        collaboration_data = {}

        try:
            # Trend and Product Correlation
            trend_product_task = {
                "type": "product_trend_correlation",
                "products": market_data.get("search_terms", []),
                "data": market_data
            }

            collab_result = await self.agents["product_discovery"].collaborate(
                "trend_analysis_agent", trend_product_task
            )

            if collab_result.get("status") == "success":
                collaboration_data["product_trend_correlation"] = collab_result["data"]

            # Opportunity Validation
            if collaboration_data:
                validation_task = {
                    "type": "opportunity_validation",
                    "opportunities": [collaboration_data],
                    "data": market_data
                }

                validation_result = await self.agents["opportunity_identification"].collaborate(
                    "product_discovery_agent", validation_task
                )

                if validation_result.get("status") == "success":
                    collaboration_data["opportunity_validation"] = validation_result["data"]

            return collaboration_data

        except Exception as e:
            logger.error(f"âŒ Agent collaboration failed: {e}")
            return {}

    async def _generate_final_recommendations(self, analysis_results: Dict[str, Any]) -> List[str]:
        """Generate final recommendations from analysis results"""
        recommendations = []

        # Extract recommendations from insights
        for insight in analysis_results["insights"]:
            recommendations.extend(insight.get("recommendations", []))

        # Add opportunity-based recommendations
        for opportunity in analysis_results["opportunities"]:
            recommendations.extend(opportunity.get("next_steps", []))

        # Deduplicate and prioritize
        unique_recommendations = list(set(recommendations))

        return unique_recommendations[:10]  # Top 10 recommendations

    async def _calculate_analysis_confidence(self, analysis_results: Dict[str, Any]) -> float:
        """Calculate overall confidence score for analysis"""
        confidence_scores = []

        # Get confidence scores from insights
        for insight in analysis_results["insights"]:
            confidence_scores.append(insight.get("confidence_score", 0.5))

        # Get confidence scores from opportunities
        for opportunity in analysis_results["opportunities"]:
            confidence_scores.append(opportunity.get("confidence_score", 0.5))

        if confidence_scores:
            return sum(confidence_scores) / len(confidence_scores)

        return 0.5

    def get_agent_status(self) -> Dict[str, Any]:
        """Get status of all agents"""
        return {
            agent_id: {
                "status": agent.status.value,
                "insights_generated": agent.insights_generated,
                "opportunities_identified": agent.opportunities_identified,
                "accuracy_score": agent.accuracy_score,
                "collaboration_count": agent.collaboration_count
            }
            for agent_id, agent in self.agents.items()
        }

# Global orchestrator instance
market_research_orchestrator: Optional[MarketResearchAgentOrchestrator] = None

async def initialize_market_research_agents(ai_service: MarketAnalysisAI, blockchain_protocol: BlockchainAgenticProtocol) -> MarketResearchAgentOrchestrator:
    """Initialize global market research agent orchestrator with learning capabilities"""
    global market_research_orchestrator

    market_research_orchestrator = MarketResearchAgentOrchestrator()
    await market_research_orchestrator.initialize(ai_service, blockchain_protocol)

    # Enable learning for all agents
    try:
        from app.agent_learning_integration import enable_agent_learning, register_learning_agent, LearningMode

        for agent_id, agent in market_research_orchestrator.agents.items():
            # Wrap each agent with learning capabilities
            learning_agent = enable_agent_learning(
                agent=agent,
                agent_name=agent_id,
                learning_mode=LearningMode.ACTIVE
            )

            # Register in the global learning registry
            register_learning_agent(agent_id, learning_agent)

            logger.info(f"ðŸŽ“ Enabled learning for agent: {agent_id}")

        logger.info("âœ¨ All market research agents now have learning capabilities enabled")
    except Exception as e:
        logger.warning(f"Failed to enable learning for agents (non-critical): {e}")

    logger.info("ðŸŽ¯ Market Research Agents ready for autonomous market analysis")
    return market_research_orchestrator

async def get_market_research_orchestrator() -> Optional[MarketResearchAgentOrchestrator]:
    """Get global market research orchestrator"""
    return market_research_orchestrator